from fastapi import FastAPI, File, UploadFile, Request
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, JSONResponse
import httpx
import numpy as np
from PIL import Image
import traceback

app = FastAPI()
templates = Jinja2Templates(directory="templates")

# Update the URL to match your model name "resnet50" instead of "resnet18"
TRITON_SERVER_URL = "http://triton-server:8000/v2/models/resnet50/infer"

@app.get("/", response_class=HTMLResponse)
async def read_form(request: Request):
    return templates.TemplateResponse("form.html", {"request": request})

def preprocess_image(image):
    """Preprocesses the input image to prepare it for Triton inference."""
    # Resize to 224x224 as specified in the model config
    image = image.resize((224, 224))
    # Convert to numpy array and normalize
    image = np.array(image).astype("float32") / 255.0
    # Normalize using ImageNet means and stds
    image = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])
    # Change to CHW format
    image = np.transpose(image, (2, 0, 1))
    # Add batch dimension
    image = np.expand_dims(image, axis=0)
    return image

@app.post("/predict")
async def predict_image(image: UploadFile = File(...)):
    try:
        # Read and preprocess the image
        image_data = Image.open(image.file)
        input_tensor = preprocess_image(image_data)
        
        # Prepare the payload with correct input name "input__0"
        payload = {
            "inputs": [
                {
                    "name": "input__0",  # Match the name in model config
                    "shape": input_tensor.shape,
                    "datatype": "FP32",
                    "data": input_tensor.flatten().tolist()
                }
            ],
            "outputs": [
                {
                    "name": "output__0"  # Match the name in model config
                }
            ]
        }

        # Send the inference request to Triton Server
        async with httpx.AsyncClient() as client:
            response = await client.post(
                TRITON_SERVER_URL,
                json=payload,
                timeout=30.0  # Add timeout for better error handling
            )
            
        if response.status_code != 200:
            return JSONResponse(
                content={
                    "error": f"Triton inference failed. Status: {response.status_code}",
                    "details": response.text
                },
                status_code=500
            )

        # Parse the response from Triton
        result = response.json()
        output_data = result["outputs"][0]["data"]
        
        # Compute probabilities and get the top 5 classes
        probabilities = np.array(output_data)
        probabilities = np.exp(probabilities) / np.sum(np.exp(probabilities))
        top5_indices = probabilities.argsort()[-5:][::-1]
        
        with open("imagenet_classes.txt", "r") as f:
            categories = [s.strip() for s in f.readlines()]
            
        predictions = {
            categories[i]: float(probabilities[i]) for i in top5_indices
        }
        
        return JSONResponse(content={"predictions": predictions})
        
    except httpx.RequestError as e:
        return JSONResponse(
            content={"error": f"Network error: {str(e)}"}, 
            status_code=500
        )
    except Exception as e:
        error_message = traceback.format_exc()
        return JSONResponse(
            content={"error": str(e), "traceback": error_message}, 
            status_code=500
        )